---
title: "YAM analysis"
author: "Nanda Jafarian"
date: "2024-09-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading libraries

```{r}
library(igraph)
library(combinat)
library(ggplot2)
library(gridExtra)
library(ggraph)
library(dplyr)
library(grid)
library(cowplot)
library(lattice)
library(RSQLite)
``` 

## Data preparation functions

```{r}

calc_avg_path_length <- function(graph) {
  mean(distances(graph)[1, -1])
}

add_avg_path_length <- function(data) {
  unique_combinations <- data %>%
    select(num_nodes, adj_mat) %>%
    distinct()
  for (i in seq_len(nrow(unique_combinations))) {
    combination <- unique_combinations[i, ]
    adj_string <- combination[[which(colnames(unique_combinations) == "adj_mat")]]
    num_nodes <- combination[[which(colnames(unique_combinations) == "num_nodes")]]
    
    adjacency_vector <- as.numeric(unlist(strsplit(adj_string, "")))
    adjacency_matrix <- matrix(adjacency_vector, nrow = num_nodes, ncol = num_nodes, byrow = TRUE)
    graph <- graph_from_adjacency_matrix(adjacency_matrix, mode = "directed")
    V(graph )$name <- as.character(1:num_nodes)
    
    avg_path_length <- calc_avg_path_length(graph)

    data[data$adj_mat == adj_string, "avg_path_length"] <- avg_path_length
  }
  data
}


calculate_path_lengths_to_root <- function(graph, root) {
  total_distance <- 0

  for(node in V(graph)) {
    if(node != root) { # Avoid considering the root itself
      all_paths <- all_simple_paths(graph, from = node, to = root, mode = "out")
      for(path in all_paths) {
        # Sum the length of nodes in each path minus 1 to get the number of edges
        total_distance <- total_distance + (length(path) - 1)
      }
    }
  }
  
  return(total_distance)
}

add_total_distance <- function(data) {
  unique_combinations <- data %>%
    select(num_nodes, adj_mat) %>%
    distinct()
  
  for (i in seq_len(nrow(unique_combinations))) {
    combination <- unique_combinations[i, ]
    adj_string <- combination[[which(colnames(unique_combinations) == "adj_mat")]]
    num_nodes <- combination[[which(colnames(unique_combinations) == "num_nodes")]]
    
    adjacency_vector <- as.numeric(unlist(strsplit(adj_string, "")))
    adjacency_matrix <- matrix(adjacency_vector, nrow = num_nodes, ncol = num_nodes, byrow = TRUE)
    
    rev_adjacency_matrix <- t(adjacency_matrix)
    graph <- graph_from_adjacency_matrix(rev_adjacency_matrix, mode = "directed")
    V(graph)$name <- as.character(1:num_nodes)
    
    
    
    root_node <- 1
    total_distance <- calculate_path_lengths_to_root(graph, root_node)
    
    data[data$adj_mat == adj_string, "total_distance"] <- total_distance
  }
  
  return(data)
}

clean_file <- function(data) {
  sum_missing <- sum(data$adj_mat == "")
  if (sum_missing > 0) {
    print(paste0("Removing ", sum_missing, " observations with missing adjacency matrices."))
  }
  data <- data[data$adj_mat != "", ]
  
  num_nodes <- data$num_nodes[1]
  sum_nan <- sum(is.nan(data$step_payoff))
  if (sum_nan > 0) {
    print(paste0("Removing ", sum_nan, " observations that failed to converge."))
  }
  data <- data[!is.nan(data$step_payoff), ]
  sum_short <- sum(data$steps < num_nodes - 1)
  return(data)
}

read_file <- function(num_nodes) {
  data <- read.csv(gzfile(paste0("./output/expected_steps_", num_nodes, ".csv.gz")), stringsAsFactors = FALSE, colClasses = c(adj_mat = "character"))
  data$strategy <- factor(
    data$strategy,
    levels = c(
    "RandomLearning",
    "PayoffBasedLearning",
    "ProximalLearning",
    "PrestigeBasedLearning",
    "ConformityBasedLearning"
    ),
    labels = c(
      "Random",
      "Payoff",
      "Proximal",
      "Prestige",
      "Conformity"
      )
    )
  return(data)
}

average_over_replications <- function(data) {
  outcome_vars <- c("step_payoff", "step_transitions")
  grouping_vars <- c("num_nodes", "alpha", "strategy", "adj_mat", "steps")
  
  data <- data %>%
    group_by(across(all_of(grouping_vars))) %>%
    summarise(across(all_of(outcome_vars), ~ mean(.x, na.rm = TRUE)), .groups = 'drop')
  
  return(data)
}

read_all <- function(numbers) {
  all_data <- lapply(numbers, function(num_nodes) {
    data <- read_file(num_nodes)
    data <- clean_file(data)
    data <- average_over_replications(data)
    data <- add_avg_path_length(data)
    return(data)
  })
  
  all_data <- bind_rows(all_data)
  
  return(all_data)
}

average_over_lambda <- function(data) {
  outcome_vars <- c("step_payoff", "step_transitions")
  other_vars_to_retain <- c("num_nodes", "alpha", "avg_path_length")
  
  lambda_values <- seq(0.1, 20, by = 0.1)

  subsets <- lapply(lambda_values, function(lambda) {
    data <- data %>%
      mutate(weight = dpois(steps, lambda))
    
    weighted_averages <- data %>%
      group_by(adj_mat, strategy, alpha) %>%
      summarize(
        across(all_of(outcome_vars), ~ sum(. * weight) / sum(weight)),
        across(all_of(other_vars_to_retain), first),
        lambda = lambda,
        .groups = 'drop'
      )

    return(weighted_averages)
  })
  
  result <- do.call(rbind, subsets)

  return(result)
}

add_ratios <- function(data) {
  data$rel_payoff <- rep(NA, nrow(data))
  data$rel_success <- rep(NA, nrow(data))
  for (i in 1:nrow(data)) {
    if (data$strategy[[i]] == "Random") {
      data$rel_payoff[[i]] <- 1
      data$rel_success[[i]] <- 1
      next
    }
    
    current_lambda <- data$lambda[[i]]
    current_adj_mat <- data$adj_mat[[i]]
    payoff <- data$step_payoff[[i]]
    success <- data$step_transitions[[i]]
    random_payoff <- data[data$lambda == current_lambda & data$adj_mat == current_adj_mat & data$strategy == "Random", "step_payoff"]
    random_success <- data[data$lambda == current_lambda & data$adj_mat == current_adj_mat & data$strategy == "Random", "step_transitions"]
    data$rel_payoff <- payoff / random_payoff
    data$rel_success <- success / random_success
  }
  
  return(data)
}

#this should do the same as the one above, but faster
add_ratios <- function(data) {
  data <- data %>%
    group_by(lambda, adj_mat, alpha) %>%
    mutate(random_payoff = ifelse(strategy == "Random", step_payoff, NA),
           random_success = ifelse(strategy == "Random", step_transitions, NA)) %>%
    mutate(random_payoff = max(random_payoff, na.rm = TRUE),
           random_success = max(random_success, na.rm = TRUE)) %>%
    mutate(rel_payoff = ifelse(strategy == "Random", 1, step_payoff / random_payoff),
           rel_success = ifelse(strategy == "Random", 1, step_transitions / random_success)) %>%
    ungroup() %>%
    select(-random_payoff, -random_success)  # Optional: remove the helper columns if not needed

  # Replace Inf and NaN from divisions by zero or NA calculations with NA
  data$rel_payoff[!is.finite(data$rel_payoff)] <- NA
  data$rel_success[!is.finite(data$rel_success)] <- NA

  return(data)
}
```

## SQLite Data preparation functions

```{r}
add_avg_path_length_SQL <- function(conn) {
  # Read distinct num_nodes and adj_mat combinations from the database
  unique_combinations <- dbGetQuery(conn, "
    SELECT DISTINCT num_nodes, adj_mat FROM expected_steps
  ")

  # Iterate over each unique combination
  for (i in seq_len(nrow(unique_combinations))) {
    combination <- unique_combinations[i, ]
    adj_string <- combination$adj_mat
    num_nodes <- combination$num_nodes
    
    # Convert adjacency matrix from string to numeric matrix
    adjacency_vector <- as.numeric(unlist(strsplit(adj_string, "")))
    adjacency_matrix <- matrix(adjacency_vector, nrow = num_nodes, ncol = num_nodes, byrow = TRUE)
    graph <- graph_from_adjacency_matrix(adjacency_matrix, mode = "directed")
    V(graph)$name <- as.character(1:num_nodes)
    
    avg_path_length <- calc_avg_path_length(graph)
    
    dbExecute(conn, "
      UPDATE expected_steps
      SET avg_path_length = ?
      WHERE adj_mat = ?
    ", params = list(avg_path_length, adj_string))
  }
}

clean_file_SQL <- function(conn) {
  sum_missing <- dbGetQuery(conn, "SELECT COUNT(*) FROM expected_steps WHERE adj_mat = ''")[[1]]
  if (sum_missing > 0) {
    print(paste0("Removing ", sum_missing, " observations with missing adjacency matrices."))
    dbExecute(conn, "DELETE FROM expected_steps WHERE adj_mat = ''")
  }
  
  num_nodes <- dbGetQuery(conn, "SELECT DISTINCT num_nodes FROM expected_steps LIMIT 1")$num_nodes[1]
  sum_nan <- dbGetQuery(conn, "SELECT COUNT(*) FROM expected_steps WHERE step_payoff IS NULL OR step_payoff != step_payoff")[[1]]
  if (sum_nan > 0) {
    print(paste0("Removing ", sum_nan, " observations that failed to converge."))
    dbExecute(conn, "DELETE FROM expected_steps WHERE step_payoff IS NULL OR step_payoff != step_payoff")
  }
  
  sum_short <- dbGetQuery(conn, paste0("SELECT COUNT(*) FROM expected_steps WHERE steps < ", num_nodes - 1))[[1]]
}

adjust_strategy_SQL <- function(conn) {
  # Define the mappings of levels to labels
  strategy_mappings <- c(
    "RandomLearning" = "Random",
    "PayoffBasedLearning" = "Payoff",
    "ProximalLearning" = "Proximal",
    "PrestigeBasedLearning" = "Prestige",
    "ConformityBasedLearning" = "Conformity"
  )
  
  for (original in names(strategy_mappings)) {
    new_label <- strategy_mappings[[original]]
    dbExecute(conn, "UPDATE expected_steps SET strategy = ? WHERE strategy = ?", params = list(new_label, original))
  }
}

average_over_replications_SQL <- function(conn) {
  
  # Disable automatic checkpoints to handle large transactions
  dbExecute(conn, "PRAGMA wal_autocheckpoint=0")
  
  # Create the new aggregated table if it doesn't already exist
  dbExecute(conn, "
    CREATE TABLE IF NOT EXISTS expected_steps_aggregated (
      num_nodes INTEGER,
      alpha REAL,
      strategy TEXT,
      adj_mat TEXT,
      steps INTEGER,
      step_payoff REAL,
      step_transitions REAL
    )
  ")

  # Possible distinct alphas
  distinct_alphas <- c(0.0, 0.5)
  # Possible distinct steps
  distinct_steps <- 1:20

  # Fetch distinct strategies and adj_mats from the database
  strategies <- dbGetQuery(conn, "SELECT DISTINCT strategy FROM expected_steps")$strategy
  adj_mats <- dbGetQuery(conn, "SELECT DISTINCT adj_mat FROM expected_steps")$adj_mat

  # Get all combinations of parameters
  combinations <- expand.grid(alpha = distinct_alphas, step = distinct_steps, strategy = strategies, adj_mat = adj_mats)

  # Define a function that each worker will execute
  worker_function <- function(combination) {
    alpha <- combination$alpha
    step <- combination$step
    strategy <- combination$strategy
    adj_mat <- combination$adj_mat

    local_conn <- dbConnect(RSQLite::SQLite(), dbname = "./output/expected_steps.sqlite")
    
    dbExecute(local_conn, "BEGIN")
    
    # Insert aggregated data for the current combination
    query <- sprintf("
      INSERT INTO expected_steps_aggregated 
      SELECT 
        num_nodes,
        alpha,
        strategy,
        adj_mat,
        steps, 
        AVG(step_payoff) AS step_payoff,
        AVG(step_transitions) AS step_transitions
      FROM expected_steps
      WHERE steps = %d AND alpha = %.1f AND strategy = '%s' AND adj_mat = '%s'
      GROUP BY num_nodes, alpha, strategy, adj_mat, steps
      ", step, alpha, strategy, adj_mat)
    
    dbExecute(local_conn, query)
    
    # Commit the transaction
    dbExecute(local_conn, "COMMIT")
    dbExecute(local_conn, "PRAGMA wal_checkpoint(FULL)")
    
    dbDisconnect(local_conn)
    return(TRUE)
  }

  # Set up cluster with a number of cores
  num_cores <- detectCores() - 1
  cl <- makeCluster(num_cores)
  
  # Export necessary variables and functions to the cluster
  clusterExport(cl, c("combinations", "worker_function", "conn"))
  
  # Apply the worker function to combinations in parallel
  parLapply(cl, seq_len(nrow(combinations)), function(i) worker_function(combinations[i, ]))

  # Stop the cluster
  stopCluster(cl)
  
  # Drop the old table and rename the new aggregated table to take its place
  dbExecute(conn, "DROP TABLE expected_steps")
  dbExecute(conn, "ALTER TABLE expected_steps_aggregated RENAME TO expected_steps")
}


average_over_lambda_SQL <- function(conn) {
  # Create the new table with the desired structure
  dbExecute(conn, "
    CREATE TABLE IF NOT EXISTS averaged_results (
      adj_mat TEXT,
      strategy TEXT,
      alpha REAL,
      num_nodes INTEGER,
      avg_path_length REAL,
      step_payoff REAL,
      step_transitions REAL,
      lambda REAL
    );
  ")

  # Clear the table if it exists
  dbExecute(conn, "DELETE FROM averaged_results")

  lambda_values <- seq(0.1, 20, by = 0.1)

  for (lambda in lambda_values) {
    # Create a weighted table using the Poisson distribution for steps
    dbExecute(conn, paste0("
      CREATE TEMPORARY TABLE temp_weighted AS
      SELECT
        adj_mat,
        strategy,
        alpha,
        num_nodes,
        avg_path_length,
        steps,
        step_payoff * dpois(steps, ", lambda, ") AS weighted_step_payoff,
        step_transitions * dpois(steps, ", lambda, ") AS weighted_step_transitions,
        dpois(steps, ", lambda, ") AS weight
      FROM expected_steps;
    "))

    # Compute weighted averages and insert into the new results table
    dbExecute(conn, "
      INSERT INTO averaged_results
      SELECT
        adj_mat,
        strategy,
        alpha,
        num_nodes,
        avg_path_length,
        SUM(weighted_step_payoff) / SUM(weight) AS step_payoff,
        SUM(weighted_step_transitions) / SUM(weight) AS step_transitions,
        ? AS lambda
      FROM 
        temp_weighted
      GROUP BY 
        adj_mat, strategy, alpha, num_nodes, avg_path_length
    ", params = list(lambda))

    # Drop the temporary table
    dbExecute(conn, "DROP TABLE IF EXISTS temp_weighted")
  }

  # Replace the original table with the aggregated results
  dbExecute(conn, "DROP TABLE IF EXISTS expected_steps")
  dbExecute(conn, "ALTER TABLE averaged_results RENAME TO expected_steps")
}

read_all_SQL <- function(conn) {
  adjust_strategy_SQL(conn)
  clean_file_SQL(conn)
  average_over_replications_SQL(conn)
  add_avg_path_length_SQL(conn)
  average_over_lambda_SQL(conn)
  print("Completed all database operations")
}

```




## Plotting functions 

```{r}

plotDVbyIV <- function(data, DV, DV_label, IV, IV_label, lambda_value) {
  average_data <- data %>%
    filter(lambda == lambda_value) %>%
    group_by(adj_mat, strategy, !!sym(IV)) %>%
    summarize(avg_DV = mean(!!sym(DV), na.rm = TRUE), .groups = 'drop')
  
  if (length(unique(data$num_nodes)) > 1) {
    num_nodes <- paste0(min(data$num_nodes), " - ", max(data$num_nodes))
  } else {
    num_nodes <- data$num_nodes[1]
  }

  plot <- ggplot(average_data, aes_string(x = IV, y = "avg_DV", color = "as.factor(strategy)")) +
    geom_point(alpha = 0.2) +
    geom_smooth(method = "loess", se = FALSE) +
    labs(
      title = paste0(DV_label, " by ", IV_label),
      subtitle = paste0("Number of nodes: ", data$num_nodes[[1]],  ", Expected number of learning opportunities λ = ", lambda_value),
      x = IV_label,
      y = DV_label
    ) +
    theme_minimal() +
    scale_color_discrete(name = "Strategy")
  
  print(plot)
  return(plot)
}


plotUnconstrained <- function(data, num_steps) {
  unconstrained_matrices <- c(
    "0100",
    "011000000",
    "0111000000000000",
    "0111100000000000000000000",
    "011111000000000000000000000000000000",
    "0111111000000000000000000000000000000000000000000",
    "0111111100000000000000000000000000000000000000000000000000000000"
  )

  if (length(unique(data$num_nodes) > 1)) {
    num_nodes <- paste0(min(data$num_nodes), " - ", max(data$num_nodes))
  } else {
    num_nodes <- data$num_nodes[1]
  }
  
  filtered_data <- data[data$adj_mat %in% unconstrained_matrices & data$step_payoff > 0,]
  
  payoff_plot <- ggplot(filtered_data, aes(x = lambda, y = step_payoff, color = strategy, group = strategy)) +
    geom_point(alpha = 0.1) + 
    geom_smooth(method = "lm", se = FALSE) + 
    theme_minimal() +
    labs(title = "Expected Payoff Per Step for Unconstrained Structures",
         subtitle = paste0("Number of Nodes: ", num_nodes),
         x = "Lambda",
         y = "Payoff per Step") +
    theme(legend.position = "right")

  print(payoff_plot)
  return(payoff_plot)
}


level_plot <- function(data, strategy, outcome, outcome_label, Y, Y_label, scale_settings,
                       lambda_resolution = 400, Y_resolution = 400) {

  # Filter data by strategy
  data <- data[data$strategy == strategy, ]
  
  # Define regular grid over lambda and the specified Y variable
  lambda_seq <- seq(min(data$lambda), max(data$lambda), length.out = lambda_resolution)
  Y_seq <- seq(min(data[[Y]]), max(data[[Y]]), length.out = Y_resolution)
  
  # Perform interpolation using akima's interp function
  interp_result <- akima::interp(
    x = data$lambda, 
    y = data[[Y]], 
    z = data[[outcome]],
    xo = lambda_seq, 
    yo = Y_seq, 
    linear = FALSE,
    duplicate = "mean"  # Handles duplicate (x, y) points
  )
  
  # Prepare data for plotting
  levelplot_data <- expand.grid(lambda = interp_result$x, Y_value = interp_result$y)
  levelplot_data[[outcome]] <- as.vector(interp_result$z)
  
  lambda_min <- min(interp_result$x)
  lambda_max <- max(interp_result$x)
  Y_min <- min(interp_result$y)
  Y_max <- max(interp_result$y)
  
  # Truncate edges by removing rows where lambda or Y are at their min/max
  truncated_data <- levelplot_data %>%
    filter(lambda != lambda_min & lambda != lambda_max & 
             Y_value != Y_min & Y_value != Y_max)

  plot <- ggplot(truncated_data, aes(x = lambda, y = Y_value)) +
    geom_tile(aes(fill = !!sym(outcome))) +
    scale_settings +
    labs(
      x = "Lambda", 
      y = Y_label,
      fill = "Outcome Value",
      title = paste("Ratio of", outcome_label, "for", strategy, "/ Random")
    ) +
    theme_minimal()
  
  # Check if a contour at z = 1 is feasible
  z_min <- min(truncated_data[[outcome]], na.rm = TRUE)
  z_max <- max(truncated_data[[outcome]], na.rm = TRUE)
  
  if (z_min <= 1 && z_max >= 1) {
    # Add contour if outcome values around 1 exist
    plot <- plot + geom_contour(aes(z = !!sym(outcome)), color = "white", linewidth = 1.5, breaks = 1, linetype = "solid")
  }
  
  return(plot)
}


get_consistent_scale <- function(all_data, outcome) {
  global_min <- min(all_data[[outcome]], na.rm = TRUE) - 2
  global_max <- max(all_data[[outcome]], na.rm = TRUE) + 2

    scale_fill_viridis_c(limits = c(global_min, global_max), option = "viridis", na.value = "transparent")
}

level_plot <- function(data, strategy, outcome, outcome_label, Y, Y_label, scale_settings,
                       lambda_resolution = 400, Y_resolution = 400) {

  library(ggplot2)
  library(mgcv)
  library(akima)
  
  # Filter data by strategy
  data <- data[data$strategy == strategy, ]
  
  # Remove any rows with missing values in relevant columns
  data <- na.omit(data[, c("lambda", Y, outcome)])
  
  # Rename Y variable to 'Y_value' to prevent conflicts
  data$Y_value <- data[[Y]]
  
  # Define regular grid over lambda and the specified Y variable for GAM smoothing
  lambda_seq <- seq(min(data$lambda), max(data$lambda), length.out = lambda_resolution)
  Y_seq <- seq(min(data$Y_value), max(data$Y_value), length.out = Y_resolution)
  
  # Create grid for predictions
  grid <- expand.grid(lambda = lambda_seq, Y_value = Y_seq)
  
  # Fit a GAM with thin plate splines for smoothing
  gam_formula <- as.formula(paste(outcome, "~ te(lambda, Y_value)"))
  gam_model <- gam(gam_formula, data = data)
  
  # Predict values on the grid (smoothed surface)
  grid[[outcome]] <- predict(gam_model, newdata = grid, type = "response")
  
  # Prepare data for plotting - Smoothed level plot
  plot <- ggplot(grid, aes(x = lambda, y = Y_value)) +
    geom_tile(aes(fill = .data[[outcome]])) +
    scale_settings +
    labs(
      x = "Lambda", 
      y = Y_label,
      fill = "Outcome Value",
      title = paste("Ratio of", outcome_label, "for", strategy, "/ Random")
    ) +
    theme_minimal()

  # Use akima to interpolate original data for contour lines
  if (nrow(data) > 3) {  # Ensure there are enough data points for interpolation
    interp_result <- with(data, akima::interp(
      x = lambda, y = Y_value, z = data[[outcome]],
      xo = lambda_seq, yo = Y_seq, 
      duplicate = "mean"
    ))

    # Check if interpolation range includes z = 1
    z_min <- min(interp_result$z, na.rm = TRUE)
    z_max <- max(interp_result$z, na.rm = TRUE)

    if (z_min <= 1 && z_max >= 1) {
      # Extract contour lines at z = 1 from interpolation
      contour_data <- contourLines(interp_result$x, interp_result$y, interp_result$z, levels = 1)
      if (length(contour_data) > 0) {
        contour_df <- do.call(rbind, lapply(contour_data, function(cont) {
          data.frame(lambda = cont$x, Y_value = cont$y)
        }))
        
        plot <- plot + geom_path(
          data = contour_df,
          aes(x = lambda, y = Y_value),
          color = "white", # Customize as needed
          size = 0.7
        )
      }
    }
  }

  return(plot)
}


```

## Analysis

```{r}

num_nodes <- 8
adjacency_matrices <- read.csv("./data/adj_mat_8.csv", header = FALSE, colClasses = "character")[,1]
alphas <- c(0.0, 0.5)
strategies <- c("RandomLearning", "PayoffBasedLearning", "ProximalLearning", "PrestigeBasedLearning", "ConformityBasedLearning")
repl <- 0
steps <- 1:20
step_payoffs <- 0
step_transitions <- 0


combinations <- expand.grid(
  num_nodes, 
  adjacency_matrices,
  alphas,
  strategies,
  repl,
  steps,
  step_payoffs,
  step_transitions
)


colnames(combinations) <- c("num_nodes", "adj_mat", "alpha", "strategy", "repl", "steps", "step_payoff", "step_transitions")


con <- gzfile("./output/expected_steps_8.csv.gz", open = "rt")
line_count <- 0

readLines(con, n = 1, warn = FALSE)

while (length(line <- readLines(con, n = 1, warn = FALSE)) > 0) {
  line_count <- line_count + 1
  if (line_count %% 10000 == 0) {
    print(paste("Processed", line_count, "lines"))
  }
  parts <- unlist(strsplit(line, ","))
  adj_mat <- parts[2]
  alpha <- as.numeric(parts[3])
  strategy <- parts[4]
  step <- as.numeric(parts[6])
  payoff <- as.numeric(parts[7])
  success <- as.numeric(parts[8])
  
  combination_idx <- which(combinations$adj_mat == adj_mat &
                           combinations$alpha == alpha &
                           combinations$strategy == strategy &
                           combinations$steps == step)

  if (length(combination_idx) > 0) {
    combinations$step_payoff[combination_idx] <- combinations$step_payoff[combination_idx] + payoff / 5040
    combinations$step_transitions[combination_idx] <- combinations$step_transitions[combination_idx] + success / 5040
  }
}
close(con)






conn <- dbConnect(SQLite(), dbname = "./output/expected_steps.sqlite")

query <- "
SELECT DISTINCT strategy
FROM (
  SELECT strategy
  FROM expected_steps
  LIMIT 10000
)
"

unique_strategies <- dbGetQuery(conn, query)

adjust_strategy_SQL(conn)
clean_file_SQL(conn)
average_over_replications_SQL(conn)
add_avg_path_length_SQL(conn)
average_over_lambda_SQL(conn)

read_all_SQL(conn)

dbDisconnect(conn)

all_data <- read_all(7)
all_data_avg <- average_over_lambda(all_data)
data <- add_ratios(all_data_avg)

saveRDS(data, "data_processed.rds")
data <- readRDS("data_processed.rds")


allsteps <- plotUnconstrained(all_data_avg, "")

payoff_settings <- get_consistent_scale(data, "rel_payoff")
a <- level_plot(data, "Payoff", "rel_payoff",  "Payoff per Step", "avg_path_length", "Average Path Length", payoff_settings)
b <- level_plot(data, "Proximal", "rel_payoff", "Payoff per Step", "avg_path_length", "Average Path Length", payoff_settings)

success_settings <- get_consistent_scale(data, "rel_success")
c <- level_plot(data, "Payoff", "rel_success", "Success Rate", "avg_path_length", "Average Path Length", success_settings)
d <- level_plot(data, "Proximal", "rel_success", "Success Rate", "avg_path_length", "Average Path Length", success_settings)

grid.arrange(a, b, c, d, ncol = 2)

payoff_plot_pl <- plotDVbyIV(
  data,
  "step_payoff", "Expected Payoff per Step",
  "avg_path_length",  "Average Path Length",
  lambda_value = 2
)

plots <- list()
for (i in 3:8) {
  plots[[i]] <- plotDVbyIV(data[data$num_nodes == i,], "step_payoff", "Expected Payoff per Step", "avg_path_length",  "Average Path Length", lambda_value = 10)
}

panel <- plot_grid(plotlist = plots[4:8], ncol = 2)

transitions_plot_pl <- plotDVbyIV(
  data,
  "step_transitions", "Expected Success Rate of Learning Attempts",
  "avg_path_length",  "Average Path Length",
  lambda_value = 2
)



hist(data[data$strategy == "Payoff" & data$lambda == 2 & data$avg_path_length > 1.3 & data$avg_path_length < 1.5, "step_payoff"][[1]], breaks = 30, main = "Expected Payoff per Step for Lambda = 2\nand average path length 1.3 - 1.5", xlab = "Expected Payoff per Step")


unconstrained_matrices <- c(
  "0100",
  "011000000",
  "0111000000000000",
  "0111100000000000000000000",
  "011111000000000000000000000000000000",
  "0111111000000000000000000000000000000000000000000",
  "0111111100000000000000000000000000000000000000000000000000000000"
)

data_unconstrained <- all_data_combined[all_data_combined$adj_mat %in% unconstrained_matrices,]
dat6 <- all_data2[all_data2$num_nodes == 6 & all_data2$adj_mat %in% unconstrained_matrices,]
```

## Isomorphism Handling
 
```{r}
remove_duplicates <- function(node_range) {
  for(num_nodes in node_range) {
    filename <- paste0("./data/adj_mat_", num_nodes, ".csv")
    data <- read.csv(filename, header = FALSE, stringsAsFactors = FALSE, colClasses = c("character"))
    colnames(data) <- c("adj_mat")
  
    unique_graphs <- list()
    unique_indices <- c()
    for (i in seq_len(nrow(data))) {
      adj_string <- data$adj_mat[i]
      adjacency_vector <- as.numeric(unlist(strsplit(adj_string, "")))
      adjacency_matrix <- matrix(adjacency_vector, nrow = num_nodes, ncol = num_nodes, byrow = TRUE)
      g <- igraph::graph_from_adjacency_matrix(adjacency_matrix, mode = "directed")
      is_duplicate <- any(sapply(unique_graphs, function(unique_g) igraph::isomorphic(unique_g, g, method = "vf2")))
      
      if (!is_duplicate) {
        unique_graphs <- append(unique_graphs, list(g))
        unique_indices <- c(unique_indices, i)  # correctly add unique index
      }
    }
  
    write.table(data[unique_indices, ], file = paste0("./data/adj_mat_new", num_nodes, ".csv"), sep = ",", row.names = FALSE, col.names = FALSE, quote = FALSE)
  }
}

remove_duplicates(8)

```

```{r}
data$adj_mat <- as.factor(data$adj_mat)
data$steps_scaled <- scale(data$steps)
library(brms)

analyze_strategy_bayes <- function(strat) {
  subset_data <- subset(data, strategy == strat)
  model <- brm(steps_scaled ~ (1|adj_mat) + (1|repl), data = subset_data, 
               family = gaussian(), cores = 4, iter = 2000)
  print(paste("Analysis for strategy:", strat))
  print(summary(model))
  
  # Calculate ICC
  post <- posterior_samples(model)
  icc_adj_mat <- post$sd_adj_mat__Intercept^2 / 
    (post$sd_adj_mat__Intercept^2 + post$sd_repl__Intercept^2 + post$sigma^2)
  icc_repl <- post$sd_repl__Intercept^2 / 
    (post$sd_adj_mat__Intercept^2 + post$sd_repl__Intercept^2 + post$sigma^2)
  
  print(paste("Mean ICC for adj_mat:", mean(icc_adj_mat)))
  print(paste("Mean ICC for repl:", mean(icc_repl)))
  
  cat("\n\n")
}

strategies <- levels(data$strategy)
lapply(strategies, analyze_strategy_bayes)

```


```{r}
plot_graph_panel <- function(df) {
  unique_adj_matrices <- df %>% 
    distinct(adj_mat, num_nodes)
  
  plot_list <- list()
  
  for (i in 1:nrow(unique_adj_matrices)) {
    adj_string <- unique_adj_matrices$adj_mat[i]
    num_nodes <- unique_adj_matrices$num_nodes[i]
    
    adjacency_vector <- as.numeric(unlist(strsplit(adj_string, "")))
    adjacency_matrix <- matrix(adjacency_vector, nrow = num_nodes, ncol = num_nodes, byrow = TRUE)
    
    g <- graph_from_adjacency_matrix(adjacency_matrix, mode = "directed")
    V(g)$name <- as.character(1:num_nodes)
    
    graph_plot <- ggraph(g, layout = "tree") +
      geom_edge_link(arrow = arrow(length = unit(2, 'mm'), type = "closed"), end_cap = circle(2, 'mm')) +
      geom_node_point(size = 2) +
      theme_void() +
      theme(
        plot.margin = unit(c(1,1,1,1), "pt"),
        panel.border = element_rect(color = "black", fill = NA, size = 0.25)
      )
    
    plot_list[[i]] <- graph_plot
  }
  
  n_plots <- length(plot_list)
  n_cols <- ceiling(sqrt(n_plots))
  n_rows <- ceiling(n_plots / n_cols)
  
  combined_plot <- plot_grid(plotlist = plot_list, ncol = n_cols, nrow = n_rows, align = 'none')
  
  pdf_width <- n_cols * 1.5
  pdf_height <- n_rows * 1.5

  print(combined_plot)
  combined_plot
}

all_data <- read_all_data(2:8)

plot <- plot_graph_panel(head(data[data$num_nodes == 8 & data$lambda == 10 & data$strategy == "Payoff" & data$step_payoff > 4 & data$avg_path_length < 1.6 & data$avg_path_length > 1.2,], 20))
```





